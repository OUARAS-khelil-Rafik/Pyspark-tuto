{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e0bd898",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 19:19:30,853 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dossier /output/4/ supprimé avec succès.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/04 19:19:31 WARN Utils: Your hostname, OUARAS-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.100.78 instead (on interface en0)\n",
      "26/01/04 19:19:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/04 19:19:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession initialisée avec succès.\n"
     ]
    }
   ],
   "source": [
    "# Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "import subprocess\n",
    "import os\n",
    "import platform\n",
    "\n",
    "def get_hdfs_bin():\n",
    "    hadoop_home = os.environ.get(\"HADOOP_HOME\")\n",
    "    if not hadoop_home:\n",
    "        raise EnvironmentError(\"HADOOP_HOME environment variable is not set.\")\n",
    "    if platform.system() == \"Windows\":\n",
    "        return os.path.join(hadoop_home, \"bin\", \"hdfs.cmd\")\n",
    "    return os.path.join(hadoop_home, \"bin\", \"hdfs\")\n",
    "\n",
    "# Supprimer le dossier si existant (forcer la suppression)\n",
    "try:\n",
    "    subprocess.run([get_hdfs_bin(), \"dfs\", \"-rm\", \"-r\", \"-f\", \"/output/4/\"], check=True)\n",
    "    print(\"Dossier /output/4/ supprimé avec succès.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"Le dossier /output/4/ n'existe peut-être pas ou une erreur est survenue :\", e)\n",
    "\n",
    "# Initialiser SparkSession avec support Hadoop\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Working with Strings & Dates\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://localhost:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.hdfs.impl\", \"org.apache.hadoop.hdfs.DistributedFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.file.impl\", \"org.apache.hadoop.fs.LocalFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.hdfs.impl.disable.cache\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"SparkSession initialisée avec succès.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17682ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emp Data & Schema\n",
    "\n",
    "emp_data = [\n",
    "    [\"001\",\"101\",\"John Doe\",\"30\",\"Male\",\"50000\",\"2015-01-01\"],\n",
    "    [\"002\",\"101\",\"Jane Smith\",\"25\",\"Female\",\"45000\",\"2016-02-15\"],\n",
    "    [\"003\",\"102\",\"Bob Brown\",\"35\",\"Male\",\"55000\",\"2014-05-01\"],\n",
    "    [\"004\",\"102\",\"Alice Lee\",\"28\",\"Female\",\"48000\",\"2017-09-30\"],\n",
    "    [\"005\",\"103\",\"Jack Chan\",\"40\",\"Male\",\"60000\",\"2013-04-01\"],\n",
    "    [\"006\",\"103\",\"Jill Wong\",\"32\",\"Female\",\"52000\",\"2018-07-01\"],\n",
    "    [\"007\",\"101\",\"James Johnson\",\"42\",\"Male\",\"70000\",\"2012-03-15\"],\n",
    "    [\"008\",\"102\",\"Kate Kim\",\"29\",\"Female\",\"51000\",\"2019-10-01\"],\n",
    "    [\"009\",\"103\",\"Tom Tan\",\"33\",\"Male\",\"58000\",\"2016-06-01\"],\n",
    "    [\"010\",\"104\",\"Lisa Lee\",\"27\",\"Female\",\"47000\",\"2018-08-01\"],\n",
    "    [\"011\",\"104\",\"David Park\",\"38\",\"Male\",\"65000\",\"2015-11-01\"],\n",
    "    [\"012\",\"105\",\"Susan Chen\",\"31\",\"Female\",\"54000\",\"2017-02-15\"],\n",
    "    [\"013\",\"106\",\"Brian Kim\",\"45\",\"Male\",\"75000\",\"2011-07-01\"],\n",
    "    [\"014\",\"107\",\"Emily Lee\",\"26\",\"Female\",\"46000\",\"2019-01-01\"],\n",
    "    [\"015\",\"106\",\"Michael Lee\",\"37\",\"Male\",\"63000\",\"2014-09-30\"],\n",
    "    [\"016\",\"107\",\"Kelly Zhang\",\"30\",\"Female\",\"49000\",\"2018-04-01\"],\n",
    "    [\"017\",\"105\",\"George Wang\",\"34\",\"Male\",\"57000\",\"2016-03-15\"],\n",
    "    [\"018\",\"104\",\"Nancy Liu\",\"29\",\"\",\"50000\",\"2017-06-01\"],\n",
    "    [\"019\",\"103\",\"Steven Chen\",\"36\",\"Male\",\"62000\",\"2015-08-01\"],\n",
    "    [\"020\",\"102\",\"Grace Kim\",\"32\",\"Female\",\"53000\",\"2018-11-01\"]\n",
    "]\n",
    "\n",
    "emp_schema = \"employee_id string, department_id string, name string, age string, gender string, salary string, hire_date string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8734c1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create emp DataFrame\n",
    "\n",
    "emp = spark.createDataFrame(data=emp_data, schema=emp_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f1f0d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+----------+\n",
      "|employee_id|department_id|         name|age|gender|salary| hire_date|\n",
      "+-----------+-------------+-------------+---+------+------+----------+\n",
      "|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|\n",
      "|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|\n",
      "|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|\n",
      "|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|\n",
      "|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|\n",
      "|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|\n",
      "|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|\n",
      "|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|\n",
      "|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|\n",
      "|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|\n",
      "|        011|          104|   David Park| 38|  Male| 65000|2015-11-01|\n",
      "|        012|          105|   Susan Chen| 31|Female| 54000|2017-02-15|\n",
      "|        013|          106|    Brian Kim| 45|  Male| 75000|2011-07-01|\n",
      "|        014|          107|    Emily Lee| 26|Female| 46000|2019-01-01|\n",
      "|        015|          106|  Michael Lee| 37|  Male| 63000|2014-09-30|\n",
      "|        016|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01|\n",
      "|        017|          105|  George Wang| 34|  Male| 57000|2016-03-15|\n",
      "|        018|          104|    Nancy Liu| 29|      | 50000|2017-06-01|\n",
      "|        019|          103|  Steven Chen| 36|  Male| 62000|2015-08-01|\n",
      "|        020|          102|    Grace Kim| 32|Female| 53000|2018-11-01|\n",
      "+-----------+-------------+-------------+---+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show emp dataframe (ACTION)\n",
    "\n",
    "emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f9cb880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: string (nullable = true)\n",
      " |-- department_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      " |-- hire_date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print Schema\n",
    "\n",
    "emp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b569c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case When\n",
    "# select employee_id, name, age, salary, gender,\n",
    "# case when gender = 'Male' then 'M' when gender = 'Female' then 'F' else null end as new_gender, hire_date from emp\n",
    "from pyspark.sql.functions import when, col, expr\n",
    "\n",
    "emp_gender_fixed = emp.withColumn(\"new_gender\", when(col(\"gender\") == 'Male', 'M')\n",
    "                                 .when(col(\"gender\") == 'Female', 'F')\n",
    "                                 .otherwise(None)\n",
    "                                 )\n",
    "                            \n",
    "emp_gender_fixed_1 = emp.withColumn(\"new_gender\", expr(\"case when gender = 'Male' then 'M' when gender = 'Female' then 'F' else null end\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d69e6051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+----------+----------+\n",
      "|employee_id|department_id|         name|age|gender|salary| hire_date|new_gender|\n",
      "+-----------+-------------+-------------+---+------+------+----------+----------+\n",
      "|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|         M|\n",
      "|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|         F|\n",
      "|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|         M|\n",
      "|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|         F|\n",
      "|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|         M|\n",
      "|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|         F|\n",
      "|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|         M|\n",
      "|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|         F|\n",
      "|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|         M|\n",
      "|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|         F|\n",
      "|        011|          104|   David Park| 38|  Male| 65000|2015-11-01|         M|\n",
      "|        012|          105|   Susan Chen| 31|Female| 54000|2017-02-15|         F|\n",
      "|        013|          106|    Brian Kim| 45|  Male| 75000|2011-07-01|         M|\n",
      "|        014|          107|    Emily Lee| 26|Female| 46000|2019-01-01|         F|\n",
      "|        015|          106|  Michael Lee| 37|  Male| 63000|2014-09-30|         M|\n",
      "|        016|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01|         F|\n",
      "|        017|          105|  George Wang| 34|  Male| 57000|2016-03-15|         M|\n",
      "|        018|          104|    Nancy Liu| 29|      | 50000|2017-06-01|      NULL|\n",
      "|        019|          103|  Steven Chen| 36|  Male| 62000|2015-08-01|         M|\n",
      "|        020|          102|    Grace Kim| 32|Female| 53000|2018-11-01|         F|\n",
      "+-----------+-------------+-------------+---+------+------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_gender_fixed_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22725fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace in Strings\n",
    "# select employee_id, name, replace(name, 'J', 'Z') as new_name, age, salary, gender, new_gender, hire_date from emp_gender_fixed\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "emp_name_fixed = emp_gender_fixed.withColumn(\"new_name\", regexp_replace(col(\"name\"), \"J\", \"Z\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d3c6f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+\n",
      "|employee_id|department_id|         name|age|gender|salary| hire_date|new_gender|     new_name|\n",
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+\n",
      "|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|         M|     Zohn Doe|\n",
      "|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|         F|   Zane Smith|\n",
      "|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|         M|    Bob Brown|\n",
      "|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|         F|    Alice Lee|\n",
      "|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|         M|    Zack Chan|\n",
      "|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|         F|    Zill Wong|\n",
      "|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|         M|Zames Zohnson|\n",
      "|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|         F|     Kate Kim|\n",
      "|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|         M|      Tom Tan|\n",
      "|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|         F|     Lisa Lee|\n",
      "|        011|          104|   David Park| 38|  Male| 65000|2015-11-01|         M|   David Park|\n",
      "|        012|          105|   Susan Chen| 31|Female| 54000|2017-02-15|         F|   Susan Chen|\n",
      "|        013|          106|    Brian Kim| 45|  Male| 75000|2011-07-01|         M|    Brian Kim|\n",
      "|        014|          107|    Emily Lee| 26|Female| 46000|2019-01-01|         F|    Emily Lee|\n",
      "|        015|          106|  Michael Lee| 37|  Male| 63000|2014-09-30|         M|  Michael Lee|\n",
      "|        016|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01|         F|  Kelly Zhang|\n",
      "|        017|          105|  George Wang| 34|  Male| 57000|2016-03-15|         M|  George Wang|\n",
      "|        018|          104|    Nancy Liu| 29|      | 50000|2017-06-01|      NULL|    Nancy Liu|\n",
      "|        019|          103|  Steven Chen| 36|  Male| 62000|2015-08-01|         M|  Steven Chen|\n",
      "|        020|          102|    Grace Kim| 32|Female| 53000|2018-11-01|         F|    Grace Kim|\n",
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_name_fixed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7da5d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date\n",
    "# select *,  to_date(hire_date, 'YYYY-MM-DD') as hire_date from emp_name_fixed\n",
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "emp_date_fix = emp_name_fixed.withColumn(\"hire_date\", to_date(col(\"hire_date\"), 'yyyy-MM-dd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c4e8ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: string (nullable = true)\n",
      " |-- department_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      " |-- hire_date: date (nullable = true)\n",
      " |-- new_gender: string (nullable = true)\n",
      " |-- new_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_date_fix.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7bf90a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Date Columns\n",
    "# Add current_date, current_timestamp, extract year from hire_date\n",
    "from pyspark.sql.functions import current_date, current_timestamp\n",
    "\n",
    "emp_dated = emp_date_fix.withColumn(\"date_now\", current_date()).withColumn(\"timestamp_now\", current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c28b637e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+----------+----------------------+\n",
      "|employee_id|department_id|name         |age|gender|salary|hire_date |new_gender|new_name     |date_now  |timestamp_now         |\n",
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+----------+----------------------+\n",
      "|001        |101          |John Doe     |30 |Male  |50000 |2015-01-01|M         |Zohn Doe     |2026-01-04|2026-01-04 19:19:36.83|\n",
      "|002        |101          |Jane Smith   |25 |Female|45000 |2016-02-15|F         |Zane Smith   |2026-01-04|2026-01-04 19:19:36.83|\n",
      "|003        |102          |Bob Brown    |35 |Male  |55000 |2014-05-01|M         |Bob Brown    |2026-01-04|2026-01-04 19:19:36.83|\n",
      "|004        |102          |Alice Lee    |28 |Female|48000 |2017-09-30|F         |Alice Lee    |2026-01-04|2026-01-04 19:19:36.83|\n",
      "|005        |103          |Jack Chan    |40 |Male  |60000 |2013-04-01|M         |Zack Chan    |2026-01-04|2026-01-04 19:19:36.83|\n",
      "|006        |103          |Jill Wong    |32 |Female|52000 |2018-07-01|F         |Zill Wong    |2026-01-04|2026-01-04 19:19:36.83|\n",
      "|007        |101          |James Johnson|42 |Male  |70000 |2012-03-15|M         |Zames Zohnson|2026-01-04|2026-01-04 19:19:36.83|\n",
      "|008        |102          |Kate Kim     |29 |Female|51000 |2019-10-01|F         |Kate Kim     |2026-01-04|2026-01-04 19:19:36.83|\n",
      "|009        |103          |Tom Tan      |33 |Male  |58000 |2016-06-01|M         |Tom Tan      |2026-01-04|2026-01-04 19:19:36.83|\n",
      "|010        |104          |Lisa Lee     |27 |Female|47000 |2018-08-01|F         |Lisa Lee     |2026-01-04|2026-01-04 19:19:36.83|\n",
      "|011        |104          |David Park   |38 |Male  |65000 |2015-11-01|M         |David Park   |2026-01-04|2026-01-04 19:19:36.83|\n",
      "|012        |105          |Susan Chen   |31 |Female|54000 |2017-02-15|F         |Susan Chen   |2026-01-04|2026-01-04 19:19:36.83|\n",
      "|013        |106          |Brian Kim    |45 |Male  |75000 |2011-07-01|M         |Brian Kim    |2026-01-04|2026-01-04 19:19:36.83|\n",
      "|014        |107          |Emily Lee    |26 |Female|46000 |2019-01-01|F         |Emily Lee    |2026-01-04|2026-01-04 19:19:36.83|\n",
      "|015        |106          |Michael Lee  |37 |Male  |63000 |2014-09-30|M         |Michael Lee  |2026-01-04|2026-01-04 19:19:36.83|\n",
      "|016        |107          |Kelly Zhang  |30 |Female|49000 |2018-04-01|F         |Kelly Zhang  |2026-01-04|2026-01-04 19:19:36.83|\n",
      "|017        |105          |George Wang  |34 |Male  |57000 |2016-03-15|M         |George Wang  |2026-01-04|2026-01-04 19:19:36.83|\n",
      "|018        |104          |Nancy Liu    |29 |      |50000 |2017-06-01|NULL      |Nancy Liu    |2026-01-04|2026-01-04 19:19:36.83|\n",
      "|019        |103          |Steven Chen  |36 |Male  |62000 |2015-08-01|M         |Steven Chen  |2026-01-04|2026-01-04 19:19:36.83|\n",
      "|020        |102          |Grace Kim    |32 |Female|53000 |2018-11-01|F         |Grace Kim    |2026-01-04|2026-01-04 19:19:36.83|\n",
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+----------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_dated.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "021efefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Null gender records\n",
    "emp_1 = emp_dated.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd7d2b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+----------+--------------------+\n",
      "|employee_id|department_id|         name|age|gender|salary| hire_date|new_gender|     new_name|  date_now|       timestamp_now|\n",
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+----------+--------------------+\n",
      "|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|         M|     Zohn Doe|2026-01-04|2026-01-04 19:19:...|\n",
      "|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|         F|   Zane Smith|2026-01-04|2026-01-04 19:19:...|\n",
      "|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|         M|    Bob Brown|2026-01-04|2026-01-04 19:19:...|\n",
      "|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|         F|    Alice Lee|2026-01-04|2026-01-04 19:19:...|\n",
      "|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|         M|    Zack Chan|2026-01-04|2026-01-04 19:19:...|\n",
      "|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|         F|    Zill Wong|2026-01-04|2026-01-04 19:19:...|\n",
      "|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|         M|Zames Zohnson|2026-01-04|2026-01-04 19:19:...|\n",
      "|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|         F|     Kate Kim|2026-01-04|2026-01-04 19:19:...|\n",
      "|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|         M|      Tom Tan|2026-01-04|2026-01-04 19:19:...|\n",
      "|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|         F|     Lisa Lee|2026-01-04|2026-01-04 19:19:...|\n",
      "|        011|          104|   David Park| 38|  Male| 65000|2015-11-01|         M|   David Park|2026-01-04|2026-01-04 19:19:...|\n",
      "|        012|          105|   Susan Chen| 31|Female| 54000|2017-02-15|         F|   Susan Chen|2026-01-04|2026-01-04 19:19:...|\n",
      "|        013|          106|    Brian Kim| 45|  Male| 75000|2011-07-01|         M|    Brian Kim|2026-01-04|2026-01-04 19:19:...|\n",
      "|        014|          107|    Emily Lee| 26|Female| 46000|2019-01-01|         F|    Emily Lee|2026-01-04|2026-01-04 19:19:...|\n",
      "|        015|          106|  Michael Lee| 37|  Male| 63000|2014-09-30|         M|  Michael Lee|2026-01-04|2026-01-04 19:19:...|\n",
      "|        016|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01|         F|  Kelly Zhang|2026-01-04|2026-01-04 19:19:...|\n",
      "|        017|          105|  George Wang| 34|  Male| 57000|2016-03-15|         M|  George Wang|2026-01-04|2026-01-04 19:19:...|\n",
      "|        019|          103|  Steven Chen| 36|  Male| 62000|2015-08-01|         M|  Steven Chen|2026-01-04|2026-01-04 19:19:...|\n",
      "|        020|          102|    Grace Kim| 32|Female| 53000|2018-11-01|         F|    Grace Kim|2026-01-04|2026-01-04 19:19:...|\n",
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99902898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Null values\n",
    "# select *, nvl('new_gender', 'O') as new_gender from emp_dated\n",
    "from pyspark.sql.functions import coalesce, lit\n",
    "\n",
    "emp_null_df = emp_dated.withColumn(\"new_gender\", coalesce(col(\"new_gender\"), lit(\"O\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b18eed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+----------+--------------------+\n",
      "|employee_id|department_id|         name|age|gender|salary| hire_date|new_gender|     new_name|  date_now|       timestamp_now|\n",
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+----------+--------------------+\n",
      "|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|         M|     Zohn Doe|2026-01-04|2026-01-04 19:19:...|\n",
      "|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|         F|   Zane Smith|2026-01-04|2026-01-04 19:19:...|\n",
      "|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|         M|    Bob Brown|2026-01-04|2026-01-04 19:19:...|\n",
      "|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|         F|    Alice Lee|2026-01-04|2026-01-04 19:19:...|\n",
      "|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|         M|    Zack Chan|2026-01-04|2026-01-04 19:19:...|\n",
      "|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|         F|    Zill Wong|2026-01-04|2026-01-04 19:19:...|\n",
      "|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|         M|Zames Zohnson|2026-01-04|2026-01-04 19:19:...|\n",
      "|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|         F|     Kate Kim|2026-01-04|2026-01-04 19:19:...|\n",
      "|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|         M|      Tom Tan|2026-01-04|2026-01-04 19:19:...|\n",
      "|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|         F|     Lisa Lee|2026-01-04|2026-01-04 19:19:...|\n",
      "|        011|          104|   David Park| 38|  Male| 65000|2015-11-01|         M|   David Park|2026-01-04|2026-01-04 19:19:...|\n",
      "|        012|          105|   Susan Chen| 31|Female| 54000|2017-02-15|         F|   Susan Chen|2026-01-04|2026-01-04 19:19:...|\n",
      "|        013|          106|    Brian Kim| 45|  Male| 75000|2011-07-01|         M|    Brian Kim|2026-01-04|2026-01-04 19:19:...|\n",
      "|        014|          107|    Emily Lee| 26|Female| 46000|2019-01-01|         F|    Emily Lee|2026-01-04|2026-01-04 19:19:...|\n",
      "|        015|          106|  Michael Lee| 37|  Male| 63000|2014-09-30|         M|  Michael Lee|2026-01-04|2026-01-04 19:19:...|\n",
      "|        016|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01|         F|  Kelly Zhang|2026-01-04|2026-01-04 19:19:...|\n",
      "|        017|          105|  George Wang| 34|  Male| 57000|2016-03-15|         M|  George Wang|2026-01-04|2026-01-04 19:19:...|\n",
      "|        018|          104|    Nancy Liu| 29|      | 50000|2017-06-01|         O|    Nancy Liu|2026-01-04|2026-01-04 19:19:...|\n",
      "|        019|          103|  Steven Chen| 36|  Male| 62000|2015-08-01|         M|  Steven Chen|2026-01-04|2026-01-04 19:19:...|\n",
      "|        020|          102|    Grace Kim| 32|Female| 53000|2018-11-01|         F|    Grace Kim|2026-01-04|2026-01-04 19:19:...|\n",
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_null_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81a92beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop old columns and Fix new column names\n",
    "emp_final = emp_null_df.drop(\"name\", \"gender\").withColumnRenamed(\"new_name\", \"name\").withColumnRenamed(\"new_gender\", \"gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8934ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+------+----------+------+-------------+----------+--------------------+\n",
      "|employee_id|department_id|age|salary| hire_date|gender|         name|  date_now|       timestamp_now|\n",
      "+-----------+-------------+---+------+----------+------+-------------+----------+--------------------+\n",
      "|        001|          101| 30| 50000|2015-01-01|     M|     Zohn Doe|2026-01-04|2026-01-04 19:19:...|\n",
      "|        002|          101| 25| 45000|2016-02-15|     F|   Zane Smith|2026-01-04|2026-01-04 19:19:...|\n",
      "|        003|          102| 35| 55000|2014-05-01|     M|    Bob Brown|2026-01-04|2026-01-04 19:19:...|\n",
      "|        004|          102| 28| 48000|2017-09-30|     F|    Alice Lee|2026-01-04|2026-01-04 19:19:...|\n",
      "|        005|          103| 40| 60000|2013-04-01|     M|    Zack Chan|2026-01-04|2026-01-04 19:19:...|\n",
      "|        006|          103| 32| 52000|2018-07-01|     F|    Zill Wong|2026-01-04|2026-01-04 19:19:...|\n",
      "|        007|          101| 42| 70000|2012-03-15|     M|Zames Zohnson|2026-01-04|2026-01-04 19:19:...|\n",
      "|        008|          102| 29| 51000|2019-10-01|     F|     Kate Kim|2026-01-04|2026-01-04 19:19:...|\n",
      "|        009|          103| 33| 58000|2016-06-01|     M|      Tom Tan|2026-01-04|2026-01-04 19:19:...|\n",
      "|        010|          104| 27| 47000|2018-08-01|     F|     Lisa Lee|2026-01-04|2026-01-04 19:19:...|\n",
      "|        011|          104| 38| 65000|2015-11-01|     M|   David Park|2026-01-04|2026-01-04 19:19:...|\n",
      "|        012|          105| 31| 54000|2017-02-15|     F|   Susan Chen|2026-01-04|2026-01-04 19:19:...|\n",
      "|        013|          106| 45| 75000|2011-07-01|     M|    Brian Kim|2026-01-04|2026-01-04 19:19:...|\n",
      "|        014|          107| 26| 46000|2019-01-01|     F|    Emily Lee|2026-01-04|2026-01-04 19:19:...|\n",
      "|        015|          106| 37| 63000|2014-09-30|     M|  Michael Lee|2026-01-04|2026-01-04 19:19:...|\n",
      "|        016|          107| 30| 49000|2018-04-01|     F|  Kelly Zhang|2026-01-04|2026-01-04 19:19:...|\n",
      "|        017|          105| 34| 57000|2016-03-15|     M|  George Wang|2026-01-04|2026-01-04 19:19:...|\n",
      "|        018|          104| 29| 50000|2017-06-01|     O|    Nancy Liu|2026-01-04|2026-01-04 19:19:...|\n",
      "|        019|          103| 36| 62000|2015-08-01|     M|  Steven Chen|2026-01-04|2026-01-04 19:19:...|\n",
      "|        020|          102| 32| 53000|2018-11-01|     F|    Grace Kim|2026-01-04|2026-01-04 19:19:...|\n",
      "+-----------+-------------+---+------+----------+------+-------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7f9c656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Write data as CSV output (ACTION)\n",
    "\n",
    "emp_final.write.format(\"csv\").mode(\"overwrite\").option(\"header\", \"true\").save(\"hdfs://localhost:9000/output/4/emp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2cb9352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus TIP\n",
    "# Convert date into String and extract date information\n",
    "from pyspark.sql.functions import date_format\n",
    "\n",
    "emp_fixed = emp_final.withColumn(\"date_year\", date_format(col(\"timestamp_now\"), \"z\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1784c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+------+----------+------+-------------+----------+--------------------+---------+\n",
      "|employee_id|department_id|age|salary| hire_date|gender|         name|  date_now|       timestamp_now|date_year|\n",
      "+-----------+-------------+---+------+----------+------+-------------+----------+--------------------+---------+\n",
      "|        001|          101| 30| 50000|2015-01-01|     M|     Zohn Doe|2026-01-04|2026-01-04 19:19:...|      CET|\n",
      "|        002|          101| 25| 45000|2016-02-15|     F|   Zane Smith|2026-01-04|2026-01-04 19:19:...|      CET|\n",
      "|        003|          102| 35| 55000|2014-05-01|     M|    Bob Brown|2026-01-04|2026-01-04 19:19:...|      CET|\n",
      "|        004|          102| 28| 48000|2017-09-30|     F|    Alice Lee|2026-01-04|2026-01-04 19:19:...|      CET|\n",
      "|        005|          103| 40| 60000|2013-04-01|     M|    Zack Chan|2026-01-04|2026-01-04 19:19:...|      CET|\n",
      "|        006|          103| 32| 52000|2018-07-01|     F|    Zill Wong|2026-01-04|2026-01-04 19:19:...|      CET|\n",
      "|        007|          101| 42| 70000|2012-03-15|     M|Zames Zohnson|2026-01-04|2026-01-04 19:19:...|      CET|\n",
      "|        008|          102| 29| 51000|2019-10-01|     F|     Kate Kim|2026-01-04|2026-01-04 19:19:...|      CET|\n",
      "|        009|          103| 33| 58000|2016-06-01|     M|      Tom Tan|2026-01-04|2026-01-04 19:19:...|      CET|\n",
      "|        010|          104| 27| 47000|2018-08-01|     F|     Lisa Lee|2026-01-04|2026-01-04 19:19:...|      CET|\n",
      "|        011|          104| 38| 65000|2015-11-01|     M|   David Park|2026-01-04|2026-01-04 19:19:...|      CET|\n",
      "|        012|          105| 31| 54000|2017-02-15|     F|   Susan Chen|2026-01-04|2026-01-04 19:19:...|      CET|\n",
      "|        013|          106| 45| 75000|2011-07-01|     M|    Brian Kim|2026-01-04|2026-01-04 19:19:...|      CET|\n",
      "|        014|          107| 26| 46000|2019-01-01|     F|    Emily Lee|2026-01-04|2026-01-04 19:19:...|      CET|\n",
      "|        015|          106| 37| 63000|2014-09-30|     M|  Michael Lee|2026-01-04|2026-01-04 19:19:...|      CET|\n",
      "|        016|          107| 30| 49000|2018-04-01|     F|  Kelly Zhang|2026-01-04|2026-01-04 19:19:...|      CET|\n",
      "|        017|          105| 34| 57000|2016-03-15|     M|  George Wang|2026-01-04|2026-01-04 19:19:...|      CET|\n",
      "|        018|          104| 29| 50000|2017-06-01|     O|    Nancy Liu|2026-01-04|2026-01-04 19:19:...|      CET|\n",
      "|        019|          103| 36| 62000|2015-08-01|     M|  Steven Chen|2026-01-04|2026-01-04 19:19:...|      CET|\n",
      "|        020|          102| 32| 53000|2018-11-01|     F|    Grace Kim|2026-01-04|2026-01-04 19:19:...|      CET|\n",
      "+-----------+-------------+---+------+----------+------+-------------+----------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_fixed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a037552",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
